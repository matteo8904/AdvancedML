{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae6f5001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from pickle import dump\n",
    "import re\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "from utils import plot_nnpredict_45\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3b1c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2134671\n",
    "\n",
    "rand = np.random.RandomState(seed)\n",
    "mInt = (1 << 15)  \n",
    "MInt = (1 << 16)  \n",
    "\n",
    "log_n = 14\n",
    "NUM = (1 << log_n)\n",
    "\n",
    "outputPrfx = \"full\"\n",
    "challengePrfx = \"challenge\"\n",
    "targetPrfx = \"target\"\n",
    "\n",
    "bounds = { \"x1\": [-np.pi, np.pi]\n",
    "         , \"x2\": [-np.pi, np.pi]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b189219f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xDF = utils.lhs_sampling(rand, NUM, bounds=bounds)\n",
    "utils.histo_params(xDF, title=\"PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf6fe1",
   "metadata": {},
   "source": [
    "### In this Lab we will train a NN to approximate a very simple function: $y = \\frac{1}{2} (\\sin(x_1) + \\cos(x_2))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "743a4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yDF = copy.deepcopy(xDF)\n",
    "y = 0.5*(np.sin(xDF[\"x1\"])+np.cos(xDF[\"x2\"]))\n",
    "yDF[\"y\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2f7ef77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.125139</td>\n",
       "      <td>0.142085</td>\n",
       "      <td>0.069838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.769255</td>\n",
       "      <td>2.837289</td>\n",
       "      <td>-0.967214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.678367</td>\n",
       "      <td>1.742410</td>\n",
       "      <td>0.411723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.759512</td>\n",
       "      <td>1.174838</td>\n",
       "      <td>-0.151437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.395503</td>\n",
       "      <td>-1.280299</td>\n",
       "      <td>0.482601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2         y\n",
       "0 -2.125139  0.142085  0.069838\n",
       "1 -1.769255  2.837289 -0.967214\n",
       "2  1.678367  1.742410  0.411723\n",
       "3 -0.759512  1.174838 -0.151437\n",
       "4  2.395503 -1.280299  0.482601"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e9767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fd9898c",
   "metadata": {},
   "source": [
    "### train test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "888180b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(yDF, test_size=0.25, random_state=rand.randint(mInt,MInt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201df98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4982ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01973151",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_hiddenLayers = 3\n",
    "N_nodes = 32\n",
    "i = keras.layers.Input(shape=(2, ))\n",
    "x = keras.layers.Dense(N_nodes, activation='swish')(i)\n",
    "c = 0\n",
    "while c < N_hiddenLayers:\n",
    "    x = keras.layers.Dense(N_nodes, activation='swish')(x)\n",
    "    c += 1\n",
    "x = keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = keras.models.Model(inputs=i, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5de9dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                96        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,297\n",
      "Trainable params: 3,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb764484",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d37ba374",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set.drop(columns=\"y\")\n",
    "y_train = train_set[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d24e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93571aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.2526 - val_loss: 0.2390\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2430 - val_loss: 0.2299\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2340 - val_loss: 0.2214\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2256 - val_loss: 0.2135\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2177 - val_loss: 0.2062\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2104 - val_loss: 0.1993\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2035 - val_loss: 0.1929\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1972 - val_loss: 0.1870\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1913 - val_loss: 0.1816\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1859 - val_loss: 0.1767\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1809 - val_loss: 0.1723\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1765 - val_loss: 0.1685\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1726 - val_loss: 0.1652\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1693 - val_loss: 0.1625\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1665 - val_loss: 0.1603\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1642 - val_loss: 0.1586\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1624 - val_loss: 0.1572\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1608 - val_loss: 0.1560\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1595 - val_loss: 0.1548\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1582 - val_loss: 0.1535\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1567 - val_loss: 0.1519\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1551 - val_loss: 0.1501\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1531 - val_loss: 0.1480\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1509 - val_loss: 0.1457\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1485 - val_loss: 0.1431\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1459 - val_loss: 0.1404\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1431 - val_loss: 0.1376\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1402 - val_loss: 0.1347\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1373 - val_loss: 0.1319\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1344 - val_loss: 0.1290\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1315 - val_loss: 0.1262\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1286 - val_loss: 0.1234\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1258 - val_loss: 0.1206\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1229 - val_loss: 0.1177\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1201 - val_loss: 0.1148\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1171 - val_loss: 0.1118\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1141 - val_loss: 0.1087\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1109 - val_loss: 0.1055\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1077 - val_loss: 0.1021\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1043 - val_loss: 0.0987\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1009 - val_loss: 0.0953\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0974 - val_loss: 0.0919\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0939 - val_loss: 0.0885\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0904 - val_loss: 0.0852\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0871 - val_loss: 0.0820\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0838 - val_loss: 0.0790\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0806 - val_loss: 0.0761\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0776 - val_loss: 0.0733\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0747 - val_loss: 0.0708\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0721 - val_loss: 0.0684\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0696 - val_loss: 0.0663\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0674 - val_loss: 0.0645\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0654 - val_loss: 0.0629\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0638 - val_loss: 0.0616\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0623 - val_loss: 0.0605\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0612 - val_loss: 0.0598\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0603 - val_loss: 0.0593\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0596 - val_loss: 0.0590\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0592 - val_loss: 0.0588\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0589 - val_loss: 0.0587\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0587 - val_loss: 0.0585\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0585 - val_loss: 0.0583\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0583 - val_loss: 0.0581\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0580 - val_loss: 0.0577\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0577 - val_loss: 0.0573\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0572 - val_loss: 0.0568\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0567 - val_loss: 0.0562\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0561 - val_loss: 0.0556\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0554 - val_loss: 0.0549\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0547 - val_loss: 0.0541\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0539 - val_loss: 0.0533\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0532 - val_loss: 0.0525\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0524 - val_loss: 0.0517\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0517 - val_loss: 0.0510\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0510 - val_loss: 0.0503\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0503 - val_loss: 0.0497\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0497 - val_loss: 0.0491\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0491 - val_loss: 0.0485\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0486 - val_loss: 0.0480\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0480 - val_loss: 0.0475\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0475 - val_loss: 0.0470\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0470 - val_loss: 0.0465\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0465 - val_loss: 0.0460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0460 - val_loss: 0.0455\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0455 - val_loss: 0.0450\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0450 - val_loss: 0.0445\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0445 - val_loss: 0.0440\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0439 - val_loss: 0.0435\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0434 - val_loss: 0.0429\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0428 - val_loss: 0.0423\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0422 - val_loss: 0.0418\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0416 - val_loss: 0.0412\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0410 - val_loss: 0.0405\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0404 - val_loss: 0.0399\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0397 - val_loss: 0.0393\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0391 - val_loss: 0.0386\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0384 - val_loss: 0.0380\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0377 - val_loss: 0.0373\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0371 - val_loss: 0.0367\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0364 - val_loss: 0.0360\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0357 - val_loss: 0.0353\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0350 - val_loss: 0.0346\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0342 - val_loss: 0.0338\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0335 - val_loss: 0.0331\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0327 - val_loss: 0.0323\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0320 - val_loss: 0.0315\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0312 - val_loss: 0.0307\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0304 - val_loss: 0.0299\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0295 - val_loss: 0.0291\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0287 - val_loss: 0.0282\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0278 - val_loss: 0.0273\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0270 - val_loss: 0.0264\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0261 - val_loss: 0.0255\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0252 - val_loss: 0.0246\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0243 - val_loss: 0.0237\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0234 - val_loss: 0.0228\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0225 - val_loss: 0.0219\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0216 - val_loss: 0.0210\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0207 - val_loss: 0.0200\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0197 - val_loss: 0.0191\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0180 - val_loss: 0.0174\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0171 - val_loss: 0.0165\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0163 - val_loss: 0.0157\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0146 - val_loss: 0.0141\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0139 - val_loss: 0.0134\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 248/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0010 - val_loss: 9.9249e-04\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.8345e-04 - val_loss: 9.7344e-04\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.6423e-04 - val_loss: 9.5487e-04\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.4551e-04 - val_loss: 9.3678e-04\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.2729e-04 - val_loss: 9.1917e-04\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.0955e-04 - val_loss: 9.0203e-04\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.9230e-04 - val_loss: 8.8537e-04\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.7552e-04 - val_loss: 8.6916e-04\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.5922e-04 - val_loss: 8.5340e-04\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.4338e-04 - val_loss: 8.3810e-04\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.2799e-04 - val_loss: 8.2323e-04\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.1306e-04 - val_loss: 8.0880e-04\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.9856e-04 - val_loss: 7.9479e-04\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.8450e-04 - val_loss: 7.8119e-04\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.7086e-04 - val_loss: 7.6800e-04\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.5763e-04 - val_loss: 7.5521e-04\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.4481e-04 - val_loss: 7.4281e-04\n",
      "Epoch 328/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 7.3238e-04 - val_loss: 7.3079e-04\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.2034e-04 - val_loss: 7.1913e-04\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.0868e-04 - val_loss: 7.0784e-04\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.9738e-04 - val_loss: 6.9690e-04\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8644e-04 - val_loss: 6.8630e-04\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.7585e-04 - val_loss: 6.7602e-04\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6559e-04 - val_loss: 6.6608e-04\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.5565e-04 - val_loss: 6.5644e-04\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.4603e-04 - val_loss: 6.4710e-04\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.3672e-04 - val_loss: 6.3806e-04\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.2771e-04 - val_loss: 6.2929e-04\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.1897e-04 - val_loss: 6.2080e-04\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.1052e-04 - val_loss: 6.1258e-04\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.0233e-04 - val_loss: 6.0460e-04\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.9440e-04 - val_loss: 5.9688e-04\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8671e-04 - val_loss: 5.8938e-04\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.7926e-04 - val_loss: 5.8212e-04\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.7205e-04 - val_loss: 5.7507e-04\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6505e-04 - val_loss: 5.6823e-04\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5826e-04 - val_loss: 5.6160e-04\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.5167e-04 - val_loss: 5.5516e-04\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.4528e-04 - val_loss: 5.4890e-04\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3908e-04 - val_loss: 5.4283e-04\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.3306e-04 - val_loss: 5.3692e-04\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 5.2721e-04 - val_loss: 5.3118e-04\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.2152e-04 - val_loss: 5.2560e-04\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.1599e-04 - val_loss: 5.2017e-04\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1062e-04 - val_loss: 5.1488e-04\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0538e-04 - val_loss: 5.0973e-04\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.0029e-04 - val_loss: 5.0472e-04\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9533e-04 - val_loss: 4.9983e-04\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.9050e-04 - val_loss: 4.9507e-04\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8579e-04 - val_loss: 4.9042e-04\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8119e-04 - val_loss: 4.8589e-04\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.7671e-04 - val_loss: 4.8146e-04\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.7234e-04 - val_loss: 4.7714e-04\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.6807e-04 - val_loss: 4.7292e-04\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6390e-04 - val_loss: 4.6879e-04\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5983e-04 - val_loss: 4.6476e-04\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.5584e-04 - val_loss: 4.6081e-04\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5195e-04 - val_loss: 4.5696e-04\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.4814e-04 - val_loss: 4.5318e-04\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.4441e-04 - val_loss: 4.4948e-04\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.4076e-04 - val_loss: 4.4586e-04\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3719e-04 - val_loss: 4.4231e-04\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.3368e-04 - val_loss: 4.3884e-04\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.3025e-04 - val_loss: 4.3543e-04\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.2689e-04 - val_loss: 4.3209e-04\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2360e-04 - val_loss: 4.2882e-04\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2037e-04 - val_loss: 4.2561e-04\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.1720e-04 - val_loss: 4.2246e-04\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.1409e-04 - val_loss: 4.1936e-04\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.1104e-04 - val_loss: 4.1633e-04\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0804e-04 - val_loss: 4.1335e-04\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0510e-04 - val_loss: 4.1042e-04\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.0221e-04 - val_loss: 4.0755e-04\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.9938e-04 - val_loss: 4.0473e-04\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9660e-04 - val_loss: 4.0195e-04\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.9386e-04 - val_loss: 3.9923e-04\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9118e-04 - val_loss: 3.9655e-04\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.8854e-04 - val_loss: 3.9392e-04\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8594e-04 - val_loss: 3.9134e-04\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.8340e-04 - val_loss: 3.8880e-04\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8089e-04 - val_loss: 3.8630e-04\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3.7843e-04 - val_loss: 3.8385e-04\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7601e-04 - val_loss: 3.8143e-04\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7363e-04 - val_loss: 3.7906e-04\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7129e-04 - val_loss: 3.7672e-04\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6899e-04 - val_loss: 3.7442e-04\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.6673e-04 - val_loss: 3.7217e-04\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.6450e-04 - val_loss: 3.6994e-04\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6231e-04 - val_loss: 3.6776e-04\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6016e-04 - val_loss: 3.6561e-04\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5804e-04 - val_loss: 3.6349e-04\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5596e-04 - val_loss: 3.6141e-04\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5391e-04 - val_loss: 3.5936e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5189e-04 - val_loss: 3.5735e-04\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4991e-04 - val_loss: 3.5536e-04\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4796e-04 - val_loss: 3.5341e-04\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.4604e-04 - val_loss: 3.5149e-04\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.4415e-04 - val_loss: 3.4960e-04\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.4229e-04 - val_loss: 3.4774e-04\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4046e-04 - val_loss: 3.4591e-04\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3866e-04 - val_loss: 3.4410e-04\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.3689e-04 - val_loss: 3.4233e-04\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3514e-04 - val_loss: 3.4058e-04\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.3342e-04 - val_loss: 3.3886e-04\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.3173e-04 - val_loss: 3.3716e-04\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3006e-04 - val_loss: 3.3549e-04\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2842e-04 - val_loss: 3.3384e-04\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2681e-04 - val_loss: 3.3222e-04\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.2522e-04 - val_loss: 3.3063e-04\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2365e-04 - val_loss: 3.2906e-04\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.2211e-04 - val_loss: 3.2751e-04\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2059e-04 - val_loss: 3.2598e-04\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1910e-04 - val_loss: 3.2448e-04\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1762e-04 - val_loss: 3.2300e-04\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1617e-04 - val_loss: 3.2154e-04\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1474e-04 - val_loss: 3.2010e-04\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1333e-04 - val_loss: 3.1868e-04\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1195e-04 - val_loss: 3.1729e-04\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1058e-04 - val_loss: 3.1591e-04\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.0923e-04 - val_loss: 3.1455e-04\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.0790e-04 - val_loss: 3.1322e-04\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.0659e-04 - val_loss: 3.1190e-04\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.0530e-04 - val_loss: 3.1060e-04\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.0403e-04 - val_loss: 3.0931e-04\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.0278e-04 - val_loss: 3.0805e-04\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.0154e-04 - val_loss: 3.0680e-04\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.0032e-04 - val_loss: 3.0557e-04\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.9912e-04 - val_loss: 3.0436e-04\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.9793e-04 - val_loss: 3.0316e-04\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9676e-04 - val_loss: 3.0198e-04\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9561e-04 - val_loss: 3.0082e-04\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9447e-04 - val_loss: 2.9967e-04\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9335e-04 - val_loss: 2.9854e-04\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9225e-04 - val_loss: 2.9742e-04\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.9115e-04 - val_loss: 2.9631e-04\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.9008e-04 - val_loss: 2.9522e-04\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.8901e-04 - val_loss: 2.9415e-04\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.8797e-04 - val_loss: 2.9309e-04\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.8693e-04 - val_loss: 2.9204e-04\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.8591e-04 - val_loss: 2.9100e-04\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8490e-04 - val_loss: 2.8998e-04\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8391e-04 - val_loss: 2.8897e-04\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8292e-04 - val_loss: 2.8798e-04\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8195e-04 - val_loss: 2.8699e-04\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8100e-04 - val_loss: 2.8602e-04\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.8005e-04 - val_loss: 2.8506e-04\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7912e-04 - val_loss: 2.8411e-04\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7820e-04 - val_loss: 2.8318e-04\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7728e-04 - val_loss: 2.8225e-04\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.7638e-04 - val_loss: 2.8134e-04\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.7550e-04 - val_loss: 2.8044e-04\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7462e-04 - val_loss: 2.7954e-04\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7375e-04 - val_loss: 2.7866e-04\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7289e-04 - val_loss: 2.7779e-04\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7205e-04 - val_loss: 2.7693e-04\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.7121e-04 - val_loss: 2.7608e-04\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7038e-04 - val_loss: 2.7523e-04\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.6956e-04 - val_loss: 2.7440e-04\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.6876e-04 - val_loss: 2.7358e-04\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6796e-04 - val_loss: 2.7276e-04\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6717e-04 - val_loss: 2.7196e-04\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.6639e-04 - val_loss: 2.7116e-04\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6561e-04 - val_loss: 2.7037e-04\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6485e-04 - val_loss: 2.6959e-04\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.6409e-04 - val_loss: 2.6882e-04\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.6335e-04 - val_loss: 2.6806e-04\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6261e-04 - val_loss: 2.6730e-04\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6188e-04 - val_loss: 2.6656e-04\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6115e-04 - val_loss: 2.6582e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6044e-04 - val_loss: 2.6509e-04\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5973e-04 - val_loss: 2.6436e-04\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5903e-04 - val_loss: 2.6365e-04\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5834e-04 - val_loss: 2.6294e-04\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5765e-04 - val_loss: 2.6224e-04\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5697e-04 - val_loss: 2.6154e-04\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5630e-04 - val_loss: 2.6085e-04\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5563e-04 - val_loss: 2.6017e-04\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5497e-04 - val_loss: 2.5950e-04\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5432e-04 - val_loss: 2.5883e-04\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5368e-04 - val_loss: 2.5817e-04\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5304e-04 - val_loss: 2.5751e-04\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.5240e-04 - val_loss: 2.5686e-04\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5178e-04 - val_loss: 2.5622e-04\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5115e-04 - val_loss: 2.5558e-04\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5054e-04 - val_loss: 2.5495e-04\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4993e-04 - val_loss: 2.5432e-04\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4933e-04 - val_loss: 2.5370e-04\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4873e-04 - val_loss: 2.5309e-04\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.4813e-04 - val_loss: 2.5248e-04\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4755e-04 - val_loss: 2.5187e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0f72c08e0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEN = len(x_train)\n",
    "patience = 50\n",
    "N_epochs = 500\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=patience)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=N_epochs, verbose=True, batch_size=LEN, validation_split=.25, \n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e1f76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_set.drop(columns=\"y\")\n",
    "y_test = test_set[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07fdeaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 0s 594us/step\n",
      "128/128 [==============================] - 0s 617us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,6))\n",
    "\n",
    "\n",
    "ax[0].plot(y_train, model.predict(x_train))\n",
    "ax[0].plot([-1,1],[-1,1], \"--\", c=\"red\")\n",
    "ax[0].set_title(\"Train Data\")\n",
    "\n",
    "ax[1].plot(y_test, model.predict(x_test))\n",
    "ax[1].plot([-1,1],[-1,1], \"--\", c=\"red\")\n",
    "ax[1].set_title(\"Test Data\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83e5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed265098",
   "metadata": {},
   "source": [
    "### Save Model & Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a40baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d111ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdlDir = f\"model_{seed}.krs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f69cb9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_2134671.krs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_2134671.krs\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ Info       : model saved to 'model_2134671.krs'\n"
     ]
    }
   ],
   "source": [
    "model.save(mdlDir)\n",
    "print(\"@ %-11s: model saved to '%s'\" %(\"Info\", mdlDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4130f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'model_{seed}_NNWeights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45491197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c705fd12",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0a387b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ Info       : loading model from directory 'model_2134671.krs'\n"
     ]
    }
   ],
   "source": [
    "print(\"@ %-11s: loading model from directory '%s'\" %(\"Info\", mdlDir))\n",
    "model = keras.models.load_model(mdlDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9cdfdda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chlng = test_set.drop(columns=\"y\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e8c8fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>0.562012</td>\n",
       "      <td>0.023201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>-1.553347</td>\n",
       "      <td>-0.040075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12446</th>\n",
       "      <td>-0.009396</td>\n",
       "      <td>1.094304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776</th>\n",
       "      <td>-0.422420</td>\n",
       "      <td>-2.086022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>2.441139</td>\n",
       "      <td>-0.393658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        x2\n",
       "2204   0.562012  0.023201\n",
       "4505  -1.553347 -0.040075\n",
       "12446 -0.009396  1.094304\n",
       "7776  -0.422420 -2.086022\n",
       "5166   2.441139 -0.393658"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chlng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30392387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 654us/step\n",
      "elapsed: 0.17182421684265137\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_chlng = model.predict(x_chlng)\n",
    "stop  = time.time()\n",
    "print('elapsed: ' + str(stop-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627f817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2569bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_hiddenLayers = 3\n",
    "N_nodes = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecbdf31",
   "metadata": {},
   "source": [
    "### Implementation on NN prediction via Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac25e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_layers = N_hiddenLayers + 1\n",
    "\n",
    "def swish(x):\n",
    "    return x/(np.exp(-x)+1)\n",
    "\n",
    "def NNFun(input1):\n",
    "    for i in range(N_layers):\n",
    "        input1 = np.dot(input1, NNWeights[i][0]) + NNWeights[i][1]\n",
    "        input1 = swish(input1)\n",
    "    i += 1\n",
    "    X = np.dot(input1, NNWeights[i][0]) + NNWeights[i][1]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f74cfc",
   "metadata": {},
   "source": [
    "### Load NN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78852bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f'model_{seed}_NNWeights.h5')\n",
    "\n",
    "NNWeights = []\n",
    "for i in range(1, len(model.layers)):\n",
    "    NNWeights.append(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d19bab38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 32), (32,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNWeights[0][0].shape, NNWeights[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3b64f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32), (32,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNWeights[1][0].shape, NNWeights[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52b9389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed: 0.012870311737060547\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_numpy = NNFun(x_chlng)\n",
    "stop  = time.time()\n",
    "y_numpy = [el[0] for el in y_numpy]\n",
    "y_numpy = np.array(y_numpy)\n",
    "print('elapsed: ' + str(stop-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13d46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edc3b0ce",
   "metadata": {},
   "source": [
    "# analytical gradient via chain rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a549a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swishPrime(x):\n",
    "    return (np.exp(-x)+1+x*np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "\n",
    "def NNGrad(input1):\n",
    "    N = len(input1) \n",
    "    # k = 0\n",
    "    input1 = np.dot(input1, NNWeights[0][0]) + NNWeights[0][1]\n",
    "    grad = np.ndarray(shape=(N, 2, N_nodes))\n",
    "    for j in range(N):\n",
    "        grad[j] = NNWeights[0][0]\n",
    "    sP = swishPrime(input1)\n",
    "    grad *= sP[:, None, :]\n",
    "    input1 = swish(input1)\n",
    "    #\n",
    "    for k in range(1,N_layers):\n",
    "        input1 = np.dot(input1, NNWeights[k][0])\n",
    "        input1 += NNWeights[k][1]\n",
    "        for n in range(N):\n",
    "            grad[n] = np.dot(grad[n], NNWeights[k][0])\n",
    "        sP = swishPrime(input1)\n",
    "        grad *= sP[:, None, :]\n",
    "        input1 = swish(input1)\n",
    "    grad = np.dot(grad, NNWeights[k+1][0])\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02e81332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 2, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNGrad(x_chlng).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b642c7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.4010507 ],\n",
       "        [ 0.00256284]],\n",
       "\n",
       "       [[-0.00119235],\n",
       "        [ 0.03895141]],\n",
       "\n",
       "       [[ 0.51444673],\n",
       "        [-0.47610499]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.50004975],\n",
       "        [-0.31843791]],\n",
       "\n",
       "       [[ 0.16639826],\n",
       "        [-0.47823207]],\n",
       "\n",
       "       [[ 0.45734905],\n",
       "        [-0.25360168]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNGrad(x_chlng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c079a765",
   "metadata": {},
   "source": [
    "### Using Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "43246cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_backprop_gradients(input1): \n",
    "    a_deriv_list = []\n",
    "    z = input1\n",
    "    for i in range(N_layers):\n",
    "        lin = np.dot(z, NNWeights[i][0]) + NNWeights[i][1]\n",
    "        z = swish(lin)\n",
    "        a_deriv_list.append(swishPrime(lin))\n",
    "        \n",
    "    a_deriv_list.append([[1] for i in range(len(input1))])\n",
    "    out = np.dot(z, NNWeights[N_layers][0]) + NNWeights[N_layers][1]\n",
    "    #print(out)\n",
    "    \n",
    "    delta_last = np.array([a_deriv_list[-1]])\n",
    "    for kk in range(N_layers, 0, -1):\n",
    "        delta_last = np.dot(delta_last, NNWeights[kk][0].T )*a_deriv_list[kk-1]\n",
    "    derivatives = np.dot(delta_last, NNWeights[0][0].T)\n",
    "    return derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5bafb7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.4010507 ,  0.00256284],\n",
       "         [-0.00119235,  0.03895141],\n",
       "         [ 0.51444673, -0.47610499],\n",
       "         ...,\n",
       "         [ 0.50004975, -0.31843791],\n",
       "         [ 0.16639826, -0.47823207],\n",
       "         [ 0.45734905, -0.25360168]]]),\n",
       " (1, 4096, 2))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_backprop_gradients(x_chlng.values), NN_backprop_gradients(x_chlng.values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556489b",
   "metadata": {},
   "source": [
    "### Using Tensorflow low level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "879cb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def NN_grad_tensorflow(input_data):\n",
    "    x_tensor = tf.convert_to_tensor(input_data, dtype=tf.float32)\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch(x_tensor)\n",
    "        output = model(x_tensor)\n",
    "    \n",
    "    result = output\n",
    "    gradients = t.gradient(output, x_tensor)\n",
    "    return gradients.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ea4cd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.40105063,  0.00256282],\n",
       "        [-0.00119238,  0.03895129],\n",
       "        [ 0.51444674, -0.476105  ],\n",
       "        ...,\n",
       "        [ 0.5000497 , -0.31843787],\n",
       "        [ 0.16639833, -0.4782321 ],\n",
       "        [ 0.45734903, -0.2536017 ]], dtype=float32),\n",
       " (4096, 2))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_grad_tensorflow(x_chlng.values), NN_grad_tensorflow(x_chlng.values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9da07f",
   "metadata": {},
   "source": [
    "### Finite Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f5fde555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_differences(input_data):\n",
    "    finite_der = np.ndarray(shape=input_data.shape)\n",
    "    h = 1e-08\n",
    "    incr_x = input_data + [h,0]\n",
    "    incr_y = input_data + [0,h]\n",
    "    print(((NNFun(incr_x) - NNFun(input_data))/h).shape)\n",
    "    finite_der[:,0] = ((NNFun(incr_x) - NNFun(input_data))/h)[:,0]\n",
    "    finite_der[:,1] = ((NNFun(incr_y) - NNFun(input_data))/h)[:,0]\n",
    "    return finite_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d7a6dbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.40105073,  0.00256285],\n",
       "       [-0.00119236,  0.03895142],\n",
       "       [ 0.51444674, -0.47610499],\n",
       "       ...,\n",
       "       [ 0.50004972, -0.3184379 ],\n",
       "       [ 0.16639825, -0.47823207],\n",
       "       [ 0.45734901, -0.25360171]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finite_differences(x_chlng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "964d1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_chlng#+[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafac37",
   "metadata": {},
   "source": [
    "### Analytical Gradients  $ \\nabla  y = ( \\frac{1}{2} \\cos(x_1), -\\frac{1}{2} \\sin(x_2)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c593639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42309227, -0.01159969],\n",
       "       [ 0.00872407,  0.02003226],\n",
       "       [ 0.49997793, -0.44430451],\n",
       "       ...,\n",
       "       [ 0.49811495, -0.35103617],\n",
       "       [ 0.17142043, -0.44208543],\n",
       "       [ 0.44682748, -0.27000505]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analitycal_der = np.ndarray(shape=x_chlng.shape)\n",
    "analitycal_der[:,0] = 0.5*np.cos(x_chlng.values[:,0])\n",
    "analitycal_der[:,1] = -0.5*np.sin(x_chlng.values[:,1])\n",
    "analitycal_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e787338e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01adb792",
   "metadata": {},
   "source": [
    "###  Why analytical gradients are differents???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b28bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086d855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc14c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
